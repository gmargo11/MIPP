import numpy as np
from scipy.stats import norm

from inference.GP_helpers import generate_grid
from planning import Planner


class ExploreExploitPathPlanner():# Planner
    def __init__(self):
        self.res = 30

    def policy(self, alpha, inference_model, loc):
        #if alpha < 0.7:
        nextSample = self.exploit(inference_model)
        #else:
        #    nextSample = self.explore(inference_model)

        # limit step size between sample & replan
        steplim = 0.3
        d_nextSample = np.linalg.norm(nextSample[0:2] - loc)
        if d_nextSample > steplim:
            nextSample[0] = (nextSample[0] - loc[0]) / d_nextSample * steplim + loc[0]
            nextSample[1] = (nextSample[1] - loc[1]) / d_nextSample * steplim + loc[1]

        return nextSample
   
    def explore(self, model):
        
        joint_distribution = model.infer_joint_distribution(res=self.res)
        independent_distribution = model.infer_independent_distribution(feature=2, res=self.res)

        ### compute predicted novelty metric
        x_candidates = np.concatenate([generate_grid(-2.0, 2.0, self.res), np.ones((self.res*self.res, 1))*0], axis=1)
        novelties = self.compute_novelties(joint_distribution, model.x_train)
        nextSample = model.x_train[1][np.argmax(novelties)]
        #nextSample = x_candidates[np.random.randint(len(x_candidates))]

        ### Sample and update model
        return nextSample #, joint_distribution, independent_distribution

    def exploit(self, model):

        joint_distribution = model.infer_joint_distribution(res=self.res)
        independent_distribution = model.infer_independent_distribution(feature=2, res=self.res)

        x_candidates = np.concatenate([generate_grid(-2.0, 2.0, self.res), np.ones((self.res*self.res, 1))*2], axis=1)
        utilities = self.compute_utilities(joint_distribution, independent_distribution, x_candidates)
        nextSample = x_candidates[np.argmax(utilities)]

        return nextSample #, joint_distribution, independent_distribution

    def compute_utilities(self, joint_distribution, independent_distribution, x_candidates):

        utilities = np.array([0.0 for candidate in x_candidates])
        y_pred = joint_distribution.predict(x_candidates)
        y_pred_obs = independent_distribution.predict(x_candidates[:, 0:2])
        
        for j in range(len(y_pred[0])):
            #utilities[j] = y_pred[0][j][0] * math.sqrt(y_pred_obs[1][j][0])
            utilities[j] = norm.cdf((y_pred[0][j][0] - 0.45) / y_pred[1][j][0]) * y_pred_obs[1][j][0]
        
        return utilities

    def compute_novelties(self, joint_distribution, x_train, feature=1):

        novelties = np.array([0.0 for candidate in x_train[feature]])
        y_pred = joint_distribution.predict(np.concatenate([x_train[feature], np.ones((len(x_train[feature]), 1))*feature], axis=1))[:][0][:]
        y_observed, y_observed_var = joint_distribution.predict(np.concatenate([x_train[2], np.ones((len(x_train[2]), 1))*feature], axis=1))[:][0:2][:]
        
        for j in range(len(y_pred)):
            novelties[j] = np.amin([abs(y_pred[j][0] - y_observed[i][0]) - y_observed_var[i][0] for i in range(len(y_observed))])

        return novelties